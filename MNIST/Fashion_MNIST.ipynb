{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Fashion_MNIST.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNX7Hed/euG+A6uKqgimbqN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/santhoshbvsrk/DeepLearning/blob/main/MNIST/Fashion_MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-RHrK4jb6xC"
      },
      "source": [
        "* Importing tensorflow package and all relevant libraries."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0RqHSOxGbx-P"
      },
      "source": [
        "import tensorflow as tf                  #import Tensorflow library\n",
        "from tensorflow import keras             #import Keras api library for tensorflow\n",
        "from keras import datasets               #import datasets provided by Keras API \n",
        "\n",
        "import numpy as np                      \n",
        "import matplotlib.pyplot as plt              "
      ],
      "execution_count": 175,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vr-uEjM3ejdj"
      },
      "source": [
        "fashion=datasets.fashion_mnist          #instantiating Fashion dataset from MNIST under Keras"
      ],
      "execution_count": 176,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qN9SHCcXuuXy"
      },
      "source": [
        "(train_images,train_labels),(test_images,test_labels)=fashion.load_data()   #loading MNIST Fashion dataset which does train & test split internally "
      ],
      "execution_count": 177,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iKhP9uWfu9KZ",
        "outputId": "c6bebe0c-63aa-4ed2-fbc1-ddec75dabe75"
      },
      "source": [
        "# checking the shape of x_train, y_train, x_test & y_test variables\n",
        "print(train_images.shape)            \n",
        "print(train_labels.shape)\n",
        "print(test_images.shape)\n",
        "print(test_labels.shape)"
      ],
      "execution_count": 178,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28)\n",
            "(60000,)\n",
            "(10000, 28, 28)\n",
            "(10000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WWwqw0XXvfH-",
        "outputId": "aa732a63-4d1c-4ed6-c306-7d3a2066bd45"
      },
      "source": [
        "train_images[0]    #checking the data present in first row of x_train"
      ],
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1,\n",
              "          0,   0,  13,  73,   0,   0,   1,   4,   0,   0,   0,   0,   1,\n",
              "          1,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
              "          0,  36, 136, 127,  62,  54,   0,   0,   0,   1,   3,   4,   0,\n",
              "          0,   3],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   6,\n",
              "          0, 102, 204, 176, 134, 144, 123,  23,   0,   0,   0,   0,  12,\n",
              "         10,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0, 155, 236, 207, 178, 107, 156, 161, 109,  64,  23,  77, 130,\n",
              "         72,  15],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   0,\n",
              "         69, 207, 223, 218, 216, 216, 163, 127, 121, 122, 146, 141,  88,\n",
              "        172,  66],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   1,   1,   0,\n",
              "        200, 232, 232, 233, 229, 223, 223, 215, 213, 164, 127, 123, 196,\n",
              "        229,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "        183, 225, 216, 223, 228, 235, 227, 224, 222, 224, 221, 223, 245,\n",
              "        173,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "        193, 228, 218, 213, 198, 180, 212, 210, 211, 213, 223, 220, 243,\n",
              "        202,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   3,   0,  12,\n",
              "        219, 220, 212, 218, 192, 169, 227, 208, 218, 224, 212, 226, 197,\n",
              "        209,  52],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   6,   0,  99,\n",
              "        244, 222, 220, 218, 203, 198, 221, 215, 213, 222, 220, 245, 119,\n",
              "        167,  56],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   4,   0,   0,  55,\n",
              "        236, 228, 230, 228, 240, 232, 213, 218, 223, 234, 217, 217, 209,\n",
              "         92,   0],\n",
              "       [  0,   0,   1,   4,   6,   7,   2,   0,   0,   0,   0,   0, 237,\n",
              "        226, 217, 223, 222, 219, 222, 221, 216, 223, 229, 215, 218, 255,\n",
              "         77,   0],\n",
              "       [  0,   3,   0,   0,   0,   0,   0,   0,   0,  62, 145, 204, 228,\n",
              "        207, 213, 221, 218, 208, 211, 218, 224, 223, 219, 215, 224, 244,\n",
              "        159,   0],\n",
              "       [  0,   0,   0,   0,  18,  44,  82, 107, 189, 228, 220, 222, 217,\n",
              "        226, 200, 205, 211, 230, 224, 234, 176, 188, 250, 248, 233, 238,\n",
              "        215,   0],\n",
              "       [  0,  57, 187, 208, 224, 221, 224, 208, 204, 214, 208, 209, 200,\n",
              "        159, 245, 193, 206, 223, 255, 255, 221, 234, 221, 211, 220, 232,\n",
              "        246,   0],\n",
              "       [  3, 202, 228, 224, 221, 211, 211, 214, 205, 205, 205, 220, 240,\n",
              "         80, 150, 255, 229, 221, 188, 154, 191, 210, 204, 209, 222, 228,\n",
              "        225,   0],\n",
              "       [ 98, 233, 198, 210, 222, 229, 229, 234, 249, 220, 194, 215, 217,\n",
              "        241,  65,  73, 106, 117, 168, 219, 221, 215, 217, 223, 223, 224,\n",
              "        229,  29],\n",
              "       [ 75, 204, 212, 204, 193, 205, 211, 225, 216, 185, 197, 206, 198,\n",
              "        213, 240, 195, 227, 245, 239, 223, 218, 212, 209, 222, 220, 221,\n",
              "        230,  67],\n",
              "       [ 48, 203, 183, 194, 213, 197, 185, 190, 194, 192, 202, 214, 219,\n",
              "        221, 220, 236, 225, 216, 199, 206, 186, 181, 177, 172, 181, 205,\n",
              "        206, 115],\n",
              "       [  0, 122, 219, 193, 179, 171, 183, 196, 204, 210, 213, 207, 211,\n",
              "        210, 200, 196, 194, 191, 195, 191, 198, 192, 176, 156, 167, 177,\n",
              "        210,  92],\n",
              "       [  0,   0,  74, 189, 212, 191, 175, 172, 175, 181, 185, 188, 189,\n",
              "        188, 193, 198, 204, 209, 210, 210, 211, 188, 188, 194, 192, 216,\n",
              "        170,   0],\n",
              "       [  2,   0,   0,   0,  66, 200, 222, 237, 239, 242, 246, 243, 244,\n",
              "        221, 220, 193, 191, 179, 182, 182, 181, 176, 166, 168,  99,  58,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,  40,  61,  44,  72,  41,  35,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0]], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RWL0SlBEyXkx",
        "outputId": "0ff481db-fdea-4534-f34d-4310ada38aa6"
      },
      "source": [
        "train_labels[0]    #checking data present in first row of y_train "
      ],
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OYhX6KRt2_5y"
      },
      "source": [
        "class_names=['T-shirt/Top','Trouser','Pullover','Dress','Coat','Sandal','Shirt','Sneaker','Bag','Ankle Boot']  #creating a variable to hold name of the target variable values."
      ],
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0yMdHjH4x6D9"
      },
      "source": [
        "#creating a function to plot images from training dataset\n",
        "def plot_sample(X,y,index):\n",
        "  plt.figure(figsize = (5,2))\n",
        "  plt.imshow(X[index])   #this function is used to print image\n",
        "  plt.xlabel(class_names[y[index]])"
      ],
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 485
        },
        "id": "OXkyY4YC2svL",
        "outputId": "dfb3c127-34e7-433f-8c71-91abd31811b7"
      },
      "source": [
        "#printing first 3 images from the training dataset by calling the above created function\n",
        "for index in range(0,3):\n",
        "  plot_sample(train_images,train_labels,index)"
      ],
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 360x144 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 360x144 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 360x144 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MfHX4MOW59pS"
      },
      "source": [
        "#normalizing dataset i.e., the value in each and image has values from 0 to 255 which is nothing but the pixel, we'll normalize it to be between 0-1. \n",
        "#Normalizing will be done on the images from both training & testing datasets\n",
        "train_images = train_images / 255.0\n",
        "test_images = test_images / 255.0"
      ],
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "59BJzpaM-cjA"
      },
      "source": [
        "from keras import models         #importing models package from Keras\n",
        "from keras import Sequential     #importing Sequential package from Keras to create a Sequential model\n",
        "from keras import layers         #importing layers package from Keras which will be used for adding Input Layers, Hidden Layers & Output Layers"
      ],
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wwaYhj09eg4g"
      },
      "source": [
        "### Model with Relu Activation and a single Hidden Layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JT5WR2hn-q2Y",
        "outputId": "b4e50dad-8d07-4348-f97b-1b4fd43f7777"
      },
      "source": [
        "model = Sequential([layers.Flatten(input_shape=(28,28)),  #we mention the input shape as the number of input pixels\n",
        "layers.Dense(100,activation='relu'),                      #This is Hidden Layer1 and 100 is the number of neurons to be created with activation function as 'relu'\n",
        "layers.Dense(10,activation='softmax')                     #This is Output Layer with 10 neurons in the output layer and here we've to mention the number of neurons as the number of output values in target variable and activation function ='softmax' for classifiction problem\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy']) #compiling model. Here loss is 'sparse_categorical_crossentropy' as it is multi class classification problem\n",
        "\n",
        "model.summary()    #printing summary of the model"
      ],
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_18\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_17 (Flatten)         (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_33 (Dense)             (None, 100)               78500     \n",
            "_________________________________________________________________\n",
            "dense_34 (Dense)             (None, 10)                1010      \n",
            "=================================================================\n",
            "Total params: 79,510\n",
            "Trainable params: 79,510\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hYX6uLUfAGrS",
        "outputId": "d32972c4-8869-478b-ddaf-81c5d33053a2"
      },
      "source": [
        "model.fit(x=train_images,y=train_labels,epochs=10,batch_size=200,verbose=1,validation_data=(test_images,test_labels)) #Fitting model on train & test data to see accuracy & loss of model"
      ],
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.2078 - accuracy: 0.9237 - val_loss: 0.3163 - val_accuracy: 0.8904\n",
            "Epoch 2/10\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.2021 - accuracy: 0.9255 - val_loss: 0.3179 - val_accuracy: 0.8903\n",
            "Epoch 3/10\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.1991 - accuracy: 0.9269 - val_loss: 0.3173 - val_accuracy: 0.8923\n",
            "Epoch 4/10\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.1971 - accuracy: 0.9278 - val_loss: 0.3179 - val_accuracy: 0.8906\n",
            "Epoch 5/10\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.1962 - accuracy: 0.9280 - val_loss: 0.3188 - val_accuracy: 0.8904\n",
            "Epoch 6/10\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.1938 - accuracy: 0.9294 - val_loss: 0.3195 - val_accuracy: 0.8916\n",
            "Epoch 7/10\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.1910 - accuracy: 0.9308 - val_loss: 0.3200 - val_accuracy: 0.8931\n",
            "Epoch 8/10\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.1891 - accuracy: 0.9303 - val_loss: 0.3209 - val_accuracy: 0.8911\n",
            "Epoch 9/10\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.1871 - accuracy: 0.9314 - val_loss: 0.3208 - val_accuracy: 0.8927\n",
            "Epoch 10/10\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.1838 - accuracy: 0.9332 - val_loss: 0.3167 - val_accuracy: 0.8945\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f200a80c310>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 157
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ItXraWR5AxMM"
      },
      "source": [
        "* From the above we see that Accuracy of Training is 93.32% & Validation is 89.45% for 10 epochs.\n",
        "* Also the Loss on Training is 0.1838 & Validation is 0.3167 for 10 epochs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DxtqF0SiFJcW"
      },
      "source": [
        "* Let us perform regularization on data to remove overfit."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vwSAa3O4Xbs6"
      },
      "source": [
        "### L2 Regularizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gVoiQU6gFXLR",
        "outputId": "63daf233-7821-4230-b6fd-b521da376be4"
      },
      "source": [
        "from keras import regularizers\n",
        "\n",
        "model_l2reg = Sequential([layers.Flatten(input_shape=(28,28)),\n",
        "layers.Dense(100,activation='relu',kernel_regularizer=regularizers.l2(0.0001)),\n",
        "layers.Dense(10,activation='softmax')\n",
        "])\n",
        "\n",
        "model_l2reg.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
        "\n",
        "model_l2reg.summary()"
      ],
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_19\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_18 (Flatten)         (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_35 (Dense)             (None, 100)               78500     \n",
            "_________________________________________________________________\n",
            "dense_36 (Dense)             (None, 10)                1010      \n",
            "=================================================================\n",
            "Total params: 79,510\n",
            "Trainable params: 79,510\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hVp_t81SGeQI",
        "outputId": "9e03f955-6c3d-4e17-a9aa-8080bcf25dcf"
      },
      "source": [
        "model_l2reg.fit(x=train_images,y=train_labels,epochs=10,batch_size=200,verbose=1,validation_data=(test_images,test_labels))"
      ],
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.8395 - accuracy: 0.7216 - val_loss: 0.5022 - val_accuracy: 0.8301\n",
            "Epoch 2/10\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4518 - accuracy: 0.8502 - val_loss: 0.4546 - val_accuracy: 0.8506\n",
            "Epoch 3/10\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4132 - accuracy: 0.8639 - val_loss: 0.4275 - val_accuracy: 0.8567\n",
            "Epoch 4/10\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3872 - accuracy: 0.8719 - val_loss: 0.4299 - val_accuracy: 0.8576\n",
            "Epoch 5/10\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3660 - accuracy: 0.8796 - val_loss: 0.4077 - val_accuracy: 0.8616\n",
            "Epoch 6/10\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.3558 - accuracy: 0.8814 - val_loss: 0.3998 - val_accuracy: 0.8663\n",
            "Epoch 7/10\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3418 - accuracy: 0.8871 - val_loss: 0.3993 - val_accuracy: 0.8686\n",
            "Epoch 8/10\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3346 - accuracy: 0.8906 - val_loss: 0.3873 - val_accuracy: 0.8728\n",
            "Epoch 9/10\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3259 - accuracy: 0.8931 - val_loss: 0.3760 - val_accuracy: 0.8742\n",
            "Epoch 10/10\n",
            "300/300 [==============================] - 1s 3ms/step - loss: 0.3125 - accuracy: 0.8982 - val_loss: 0.3804 - val_accuracy: 0.8750\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f2007624dd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 159
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ox4AS2fuWvuD"
      },
      "source": [
        "* From the above we see that Accuracy of Training is 89.82% & Validation is 87.5% for 10 epochs.\n",
        "* Also the Loss on Training is 0.3125 & Validation is 0.3804 for 10 epochs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "STMPnUksXVGx"
      },
      "source": [
        "### L1 Regularizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j1q1lnJHHX9S",
        "outputId": "2a01a673-65b6-40be-ae5d-64144677c0e9"
      },
      "source": [
        "from keras import regularizers\n",
        "\n",
        "model_l1reg = Sequential([layers.Flatten(input_shape=(28,28)),\n",
        "layers.Dense(100,activation='relu',kernel_regularizer=regularizers.l1(0.0001)),\n",
        "layers.Dense(10,activation='softmax')\n",
        "])\n",
        "\n",
        "model_l1reg.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
        "\n",
        "model_l1reg.summary()"
      ],
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_20\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_19 (Flatten)         (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_37 (Dense)             (None, 100)               78500     \n",
            "_________________________________________________________________\n",
            "dense_38 (Dense)             (None, 10)                1010      \n",
            "=================================================================\n",
            "Total params: 79,510\n",
            "Trainable params: 79,510\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NFuP0ii5Ht0v",
        "outputId": "23a99e3b-3c8f-45fc-eb23-80e5c0c5e2f9"
      },
      "source": [
        "model_l1reg.fit(x=train_images,y=train_labels,epochs=10,batch_size=200,verbose=1,validation_data=(test_images,test_labels))"
      ],
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 1.1274 - accuracy: 0.7197 - val_loss: 0.7052 - val_accuracy: 0.8283\n",
            "Epoch 2/10\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.6543 - accuracy: 0.8435 - val_loss: 0.6265 - val_accuracy: 0.8420\n",
            "Epoch 3/10\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.5797 - accuracy: 0.8568 - val_loss: 0.5924 - val_accuracy: 0.8479\n",
            "Epoch 4/10\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.5527 - accuracy: 0.8585 - val_loss: 0.5658 - val_accuracy: 0.8471\n",
            "Epoch 5/10\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.5140 - accuracy: 0.8677 - val_loss: 0.5288 - val_accuracy: 0.8575\n",
            "Epoch 6/10\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4953 - accuracy: 0.8710 - val_loss: 0.5367 - val_accuracy: 0.8549\n",
            "Epoch 7/10\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4797 - accuracy: 0.8721 - val_loss: 0.5150 - val_accuracy: 0.8596\n",
            "Epoch 8/10\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4680 - accuracy: 0.8746 - val_loss: 0.4908 - val_accuracy: 0.8626\n",
            "Epoch 9/10\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4579 - accuracy: 0.8739 - val_loss: 0.5041 - val_accuracy: 0.8532\n",
            "Epoch 10/10\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4476 - accuracy: 0.8765 - val_loss: 0.4858 - val_accuracy: 0.8591\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f20085e35d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 161
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8baDSIu7Xz4i"
      },
      "source": [
        "* From the above we see that Accuracy of Training is 87.65% & Validation is 85.91% for 10 epochs.\n",
        "* Also the Loss on Training is 0.4476 & Validation is 0.4858 for 10 epochs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DOrnIgLmYHRt"
      },
      "source": [
        "### L1 Regularizer with 2 Hidden Layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uml94zaKKPQg",
        "outputId": "5205838f-1629-4277-ae44-e8abb1566a1e"
      },
      "source": [
        "from keras import regularizers\n",
        "\n",
        "model_l1reg_2layers = Sequential([layers.Flatten(input_shape=(28,28)),\n",
        "layers.Dense(100,activation='relu',kernel_regularizer=regularizers.l1(0.0001)),\n",
        "layers.Dense(80,activation='relu',kernel_regularizer=regularizers.l1(0.0001)),\n",
        "layers.Dense(10,activation='softmax')\n",
        "])\n",
        "\n",
        "model_l1reg_2layers.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
        "\n",
        "model_l1reg_2layers.summary()"
      ],
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_21\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_20 (Flatten)         (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_39 (Dense)             (None, 100)               78500     \n",
            "_________________________________________________________________\n",
            "dense_40 (Dense)             (None, 80)                8080      \n",
            "_________________________________________________________________\n",
            "dense_41 (Dense)             (None, 10)                810       \n",
            "=================================================================\n",
            "Total params: 87,390\n",
            "Trainable params: 87,390\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KkEtJ6sENhTr",
        "outputId": "9f6eb3ff-7d68-43af-f00a-60b0b2e6bf66"
      },
      "source": [
        "model_l1reg_2layers.fit(x=train_images,y=train_labels,epochs=10,batch_size=200,verbose=1,validation_data=(test_images,test_labels))"
      ],
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "300/300 [==============================] - 2s 5ms/step - loss: 1.2046 - accuracy: 0.7167 - val_loss: 0.7375 - val_accuracy: 0.8318\n",
            "Epoch 2/10\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.6878 - accuracy: 0.8496 - val_loss: 0.6455 - val_accuracy: 0.8506\n",
            "Epoch 3/10\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.6157 - accuracy: 0.8635 - val_loss: 0.6070 - val_accuracy: 0.8542\n",
            "Epoch 4/10\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.5752 - accuracy: 0.8661 - val_loss: 0.5981 - val_accuracy: 0.8513\n",
            "Epoch 5/10\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.5365 - accuracy: 0.8726 - val_loss: 0.5697 - val_accuracy: 0.8554\n",
            "Epoch 6/10\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.5090 - accuracy: 0.8777 - val_loss: 0.5435 - val_accuracy: 0.8643\n",
            "Epoch 7/10\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4986 - accuracy: 0.8771 - val_loss: 0.5549 - val_accuracy: 0.8556\n",
            "Epoch 8/10\n",
            "300/300 [==============================] - 1s 5ms/step - loss: 0.4826 - accuracy: 0.8809 - val_loss: 0.5226 - val_accuracy: 0.8628\n",
            "Epoch 9/10\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4664 - accuracy: 0.8828 - val_loss: 0.5069 - val_accuracy: 0.8667\n",
            "Epoch 10/10\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4542 - accuracy: 0.8861 - val_loss: 0.4975 - val_accuracy: 0.8708\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f2007ba9690>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 164
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "abIBim1kYb0c"
      },
      "source": [
        "* From the above we see that Accuracy of Training is 88.61% & Validation is 87.08% for 10 epochs.\n",
        "* Also the Loss on Training is 0.4542 & Validation is 0.4975 for 10 epochs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jztjoUkUYtLE"
      },
      "source": [
        "### 25% Dropout with 2 Hidden Layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "URmwh4goRqum",
        "outputId": "25dbd3a0-0c8e-4f16-bc59-83c832381159"
      },
      "source": [
        "from keras.layers import Dense\n",
        "from keras.layers.core import Dropout\n",
        "\n",
        "model_2layers_do = Sequential()\n",
        "\n",
        "model_2layers_do.add(layers.Flatten(input_shape=(28,28)))\n",
        "model_2layers_do.add(Dense(100,activation='relu')), Dropout(0.25)\n",
        "model_2layers_do.add(Dense(80,activation='relu')), Dropout(0.25)\n",
        "model_2layers_do.add(Dense(10,activation='softmax'))\n",
        "\n",
        "model_2layers_do.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['acc'])\n",
        "\n",
        "model_2layers_do.summary()"
      ],
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_23\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_22 (Flatten)         (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_45 (Dense)             (None, 100)               78500     \n",
            "_________________________________________________________________\n",
            "dense_46 (Dense)             (None, 80)                8080      \n",
            "_________________________________________________________________\n",
            "dense_47 (Dense)             (None, 10)                810       \n",
            "=================================================================\n",
            "Total params: 87,390\n",
            "Trainable params: 87,390\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LDef9Zm8TQ-6",
        "outputId": "7e929286-4bee-43b4-d5ee-ee253a968d58"
      },
      "source": [
        "model_2layers_do.fit(x=train_images,y=train_labels,epochs=10,batch_size=200,verbose=1,validation_data=(test_images,test_labels))"
      ],
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "300/300 [==============================] - 2s 5ms/step - loss: 0.8541 - acc: 0.7109 - val_loss: 0.4540 - val_acc: 0.8367\n",
            "Epoch 2/10\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4169 - acc: 0.8526 - val_loss: 0.4068 - val_acc: 0.8551\n",
            "Epoch 3/10\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3668 - acc: 0.8658 - val_loss: 0.4329 - val_acc: 0.8443\n",
            "Epoch 4/10\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3402 - acc: 0.8768 - val_loss: 0.3770 - val_acc: 0.8670\n",
            "Epoch 5/10\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3240 - acc: 0.8818 - val_loss: 0.3540 - val_acc: 0.8743\n",
            "Epoch 6/10\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.2932 - acc: 0.8928 - val_loss: 0.3522 - val_acc: 0.8732\n",
            "Epoch 7/10\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.2865 - acc: 0.8947 - val_loss: 0.3430 - val_acc: 0.8760\n",
            "Epoch 8/10\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.2706 - acc: 0.9002 - val_loss: 0.3428 - val_acc: 0.8754\n",
            "Epoch 9/10\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.2651 - acc: 0.9029 - val_loss: 0.3386 - val_acc: 0.8752\n",
            "Epoch 10/10\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.2577 - acc: 0.9052 - val_loss: 0.3377 - val_acc: 0.8781\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f20196d5810>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 168
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ynEeloPMZSOG"
      },
      "source": [
        "* From the above we see that Accuracy of Training is 90.52% & Validation is 87.81% for 10 epochs.\n",
        "* Also the Loss on Training is 0.2577 & Validation is 0.3377 for 10 epochs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-hS9bKKNZgr_"
      },
      "source": [
        "### Early Stopping Callback with 2 Hidden Layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iPBqcrFDTguD",
        "outputId": "9ce9dad3-fa71-4ee8-9f27-ea6f4dd739b7"
      },
      "source": [
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "model_2layers_es = Sequential()\n",
        "\n",
        "model_2layers_es.add(layers.Flatten(input_shape=(28,28)))\n",
        "model_2layers_es.add(Dense(100,activation='relu'))\n",
        "model_2layers_es.add(Dense(80,activation='relu'))\n",
        "model_2layers_es.add(Dense(10,activation='softmax'))\n",
        "\n",
        "model_2layers_es.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['acc'])\n",
        "\n",
        "model_2layers_es.summary()"
      ],
      "execution_count": 170,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_25\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_24 (Flatten)         (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_51 (Dense)             (None, 100)               78500     \n",
            "_________________________________________________________________\n",
            "dense_52 (Dense)             (None, 80)                8080      \n",
            "_________________________________________________________________\n",
            "dense_53 (Dense)             (None, 10)                810       \n",
            "=================================================================\n",
            "Total params: 87,390\n",
            "Trainable params: 87,390\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zk4hOy1xaEmZ",
        "outputId": "7ee0e552-54eb-4336-bf4d-22b96f126d53"
      },
      "source": [
        "model_2layers_es.fit(x=train_images,y=train_labels,epochs=10,validation_data=(test_images,test_labels),callbacks=[EarlyStopping(monitor='val_acc', patience=2)])"
      ],
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1377 - acc: 0.9476 - val_loss: 0.4283 - val_acc: 0.8890\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1338 - acc: 0.9481 - val_loss: 0.4398 - val_acc: 0.8874\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1312 - acc: 0.9499 - val_loss: 0.4517 - val_acc: 0.8842\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f2007799e50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 174
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t1kkl1DiaKBl"
      },
      "source": [
        "* From the above we see that Accuracy of Training is 94.99% & Validation is 88.42% for 10 epochs.\n",
        "* Also the Loss on Training is 0.1312 & Validation is 0.4517 for 10 epochs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kfq9Y_mfhNTh"
      },
      "source": [
        "### Predicting the target values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GjBSwJRlhURP"
      },
      "source": [
        "predictions_es = model_2layers_es.predict(test_images) #predicting value using the Early Stopping model."
      ],
      "execution_count": 180,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_eolC8xxhppC",
        "outputId": "5878d610-6fc2-40a4-e87d-a3ab37c833fe"
      },
      "source": [
        "print(\"Predicted Value of {} image from Test Data is: {}\".format(0,predictions_es[0])) # this gives the one hot encoding value of the target variable for the provided index.\n",
        "print(\"Predicted Value of {} image from Test Data is: {}\".format(0,np.argmax(predictions_es[0]))) #this gives the value of prediction.\n",
        "print(\"Actual value of {} image is: {}\".format(0,test_labels[0])) #this gives the actual value"
      ],
      "execution_count": 184,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicted Value of 0 image from Test Data is: [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            "Predicted Value of 0 image from Test Data is: 9\n",
            "Actual value of 0 image is: 9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bke7s8fqjS9h"
      },
      "source": [
        "### Conclusion\n",
        "\n",
        "* This shows that actual & predicted value for a particular index '0' are same and our prediction is correct.\n",
        "\n",
        "* We can repeat this process by choosing a model where the validation accuracy is less."
      ]
    }
  ]
}